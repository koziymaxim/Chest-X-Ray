{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas -q\n",
    "%pip install matplotlib -q\n",
    "%pip install kagglehub -q\n",
    "%pip install tensorflow -q\n",
    "%pip install scikit-learn -q\n",
    "%pip install seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T20:50:32.167650Z",
     "iopub.status.busy": "2025-05-28T20:50:32.167362Z",
     "iopub.status.idle": "2025-05-28T20:50:52.270652Z",
     "shell.execute_reply": "2025-05-28T20:50:52.269448Z",
     "shell.execute_reply.started": "2025-05-28T20:50:32.167627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, AvgPool2D, MaxPool2D, GlobalAveragePooling2D, Dropout, BatchNormalization \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим данные\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# преднастройка формаирование датасета\n",
    "settings_loading_data = dict(\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    color_mode='grayscale', # если использовать предобученную ч/б модель, то изменить этот параметр на 'grayscale'\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    interpolation='nearest', # Попробовать: bicubic (лучшая, но тяжёлая) lanczos3/5 (вроде норм), было nearest\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 files belonging to 2 classes.\n",
      "Found 16 files belonging to 2 classes.\n",
      "Found 624 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# сформируем датасеты\n",
    "df_train = image_dataset_from_directory(\n",
    "    path + '/chest_xray/train',\n",
    "    shuffle=True,\n",
    "    **settings_loading_data\n",
    ")\n",
    "\n",
    "df_valid = image_dataset_from_directory(\n",
    "    path + '/chest_xray/val',\n",
    "    shuffle=False,\n",
    "    **settings_loading_data\n",
    ")\n",
    "\n",
    "df_test = image_dataset_from_directory(\n",
    "    path + '/chest_xray/test',\n",
    "    shuffle=False,\n",
    "    **settings_loading_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классы: ['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "# вывод 9 фотографий из датасета для примера\n",
    "class_names = df_train.class_names\n",
    "print(\"Классы:\", class_names)\n",
    "\n",
    "# for images, labels in df_train.take(1):\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\").squeeze(), cmap='gray') \n",
    "#         plt.title(f\"Class: {class_names[int(labels[i].numpy().item())]}\")\n",
    "#         plt.axis(\"off\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Новый размер train (батчей): 132\n",
      "Новый размер valid (батчей): 32\n"
     ]
    }
   ],
   "source": [
    "# т.к. 16 изображений валидационной выборки - это очень мало, то объединим test с val, а потом разобьем их\n",
    "df_train_full = df_train.concatenate(df_valid)\n",
    "val_size = int(len(df_train_full) * 0.2)\n",
    "\n",
    "df_valid = df_train_full.take(val_size)\n",
    "df_train = df_train_full.skip(val_size)\n",
    "\n",
    "print(f\"Новый размер train (батчей): {len(df_train)}\")\n",
    "print(f\"Новый размер valid (батчей): {len(df_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс NORMAL (0): 1067 изображений\n",
      "Класс PNEUMONIA (1): 3141 изображений\n"
     ]
    }
   ],
   "source": [
    "# проверим баланс классов\n",
    "# TODO - сделать попроще это ячейку\n",
    "labels = []\n",
    "for _, label_batch in df_train:\n",
    "    labels.extend(label_batch.numpy())\n",
    "\n",
    "normal_count = np.sum(np.array(labels) == 0)\n",
    "pneumonia_count = np.sum(np.array(labels) == 1)\n",
    "\n",
    "print(f\"Класс NORMAL (0): {normal_count} изображений\")\n",
    "print(f\"Класс PNEUMONIA (1): {pneumonia_count} изображений\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настроим аугментацию\n",
    "# 1. будем поворачивать фотографии, на 10 градусов в разные стороны\n",
    "# 2. смещаем фотографии по вертикали и горизонатли на 10 процентов\n",
    "# 3. зумим фотографии на 20 процентов\n",
    "data_augmentation_pipeline = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(factor=10/360.0, fill_mode=\"nearest\", interpolation=\"bilinear\"),\n",
    "    tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1, fill_mode=\"nearest\", interpolation=\"bilinear\"),\n",
    "    tf.keras.layers.RandomZoom(height_factor=0.2, width_factor=0.2, fill_mode=\"nearest\", interpolation=\"bilinear\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для нормализации\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Приводит значения пикселей к диапазону [0, 1].\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "# Функция аугментации и нормализации для ТРЕНИРОВОЧНЫХ данных\n",
    "def augment_and_normalize_train(image, label):\n",
    "    \"\"\"Применяет аугментацию и затем нормализует изображение.\"\"\"\n",
    "    image_augmented = data_augmentation_pipeline(image, training=True)\n",
    "    return tf.cast(image_augmented, tf.float32) / 255.0, label\n",
    "\n",
    "# Применяем новые функции к нашим датасетам\n",
    "# Важно: аугментацию применяем ТОЛЬКО к df_train\n",
    "df_train_processed = df_train.map(augment_and_normalize_train, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "df_valid_processed = df_valid.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "df_test_processed = df_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс NORMAL (0): 1077 изображений\n",
      "Класс PNEUMONIA (1): 3131 изображений\n"
     ]
    }
   ],
   "source": [
    "# проверим баланс классов\n",
    "# TODO - сделать попроще это ячейку\n",
    "labels = []\n",
    "for _, label_batch in df_train_processed:\n",
    "    labels.extend(label_batch.numpy())\n",
    "\n",
    "normal_count = np.sum(np.array(labels) == 0)\n",
    "pneumonia_count = np.sum(np.array(labels) == 1)\n",
    "\n",
    "print(f\"Класс NORMAL (0): {normal_count} изображений\")\n",
    "print(f\"Класс PNEUMONIA (1): {pneumonia_count} изображений\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 18:22:09.786192: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем class_weights\n",
    "# сделаем это через кол-во элементов одного и второго класса\n",
    "labels = np.concatenate([y for x, y in df_train_processed], axis=0)\n",
    "normal_count = np.sum(labels == 0)\n",
    "pneumonia_count = np.sum(labels == 1)\n",
    "total_count = len(labels)\n",
    "\n",
    "weight_for_0 = (1 / normal_count) * (total_count / 2)\n",
    "weight_for_1 = (1 / pneumonia_count) * (total_count / 2)\n",
    "\n",
    "class_weights = {0: weight_for_0, 1: weight_for_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koziy/projects/xray_env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# создадим модель\n",
    "# tf.keras.backend.set_image_data_format('channels_last')\n",
    "# backbone = ResNet50(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False)\n",
    "# backbone.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(backbone)\n",
    "\n",
    "# --- БЛОК 1: Входной блок, ищем самые простые признаки ---\n",
    "# Входное изображение: (224, 224, 3)\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "# Выход: (112, 112, 32)\n",
    "\n",
    "# --- БЛОК 2: Увеличиваем количество фильтров ---\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "# Выход: (56, 56, 64)\n",
    "\n",
    "# --- БЛОК 3: Еще больше фильтров, добавляем Dropout ---\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Dropout(0.2)) # Небольшой Dropout для сверточной части\n",
    "# Выход: (28, 28, 128)\n",
    "\n",
    "# --- БЛОК 4: Максимальное количество фильтров ---\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "# Выход: (14, 14, 256)\n",
    "\n",
    "# --- ГОЛОВА: Преобразование признаков в финальное решение ---\n",
    "model.add(Flatten())\n",
    "\n",
    "# Плотный слой для комбинации признаков\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5)) # Агрессивный Dropout для плотной части\n",
    "    \n",
    "    # Выходной слой\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=Adam(learning_rate=1e-3), \n",
    "    metrics=[\n",
    "        'accuracy',       \n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "# history_head = model.fit(\n",
    "#     df_train_processed,\n",
    "#     validation_data=df_valid_processed,\n",
    "#     class_weight=class_weights,\n",
    "#     epochs=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.8122 - auc: 0.9131 - loss: 0.4637 - precision: 0.9605 - recall: 0.7804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 163ms/step - accuracy: 0.8125 - auc: 0.9133 - loss: 0.4629 - precision: 0.9606 - recall: 0.7807 - val_accuracy: 0.7266 - val_auc: 0.5000 - val_loss: 7.1539 - val_precision: 0.7266 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9097 - auc: 0.9691 - loss: 0.2332 - precision: 0.9747 - recall: 0.9022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.9097 - auc: 0.9691 - loss: 0.2333 - precision: 0.9746 - recall: 0.9022 - val_accuracy: 0.7188 - val_auc: 0.5629 - val_loss: 1.2950 - val_precision: 0.7330 - val_recall: 0.9721 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9064 - auc: 0.9715 - loss: 0.2245 - precision: 0.9767 - recall: 0.8931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 103ms/step - accuracy: 0.9064 - auc: 0.9715 - loss: 0.2244 - precision: 0.9766 - recall: 0.8932 - val_accuracy: 0.7246 - val_auc: 0.9122 - val_loss: 1.1930 - val_precision: 0.7275 - val_recall: 0.9946 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 103ms/step - accuracy: 0.9336 - auc: 0.9780 - loss: 0.1830 - precision: 0.9823 - recall: 0.9269 - val_accuracy: 0.7275 - val_auc: 0.5000 - val_loss: 4.0050 - val_precision: 0.7275 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9097 - auc: 0.9692 - loss: 0.2286 - precision: 0.9754 - recall: 0.9022\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 102ms/step - accuracy: 0.9097 - auc: 0.9692 - loss: 0.2288 - precision: 0.9754 - recall: 0.9023 - val_accuracy: 0.7266 - val_auc: 0.5839 - val_loss: 1.8781 - val_precision: 0.7263 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9373 - auc: 0.9868 - loss: 0.1474 - precision: 0.9881 - recall: 0.9270"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - accuracy: 0.9372 - auc: 0.9868 - loss: 0.1476 - precision: 0.9880 - recall: 0.9270 - val_accuracy: 0.9014 - val_auc: 0.9853 - val_loss: 0.2388 - val_precision: 0.8861 - val_recall: 0.9919 - learning_rate: 2.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 98ms/step - accuracy: 0.9341 - auc: 0.9846 - loss: 0.1559 - precision: 0.9873 - recall: 0.9236 - val_accuracy: 0.8691 - val_auc: 0.9771 - val_loss: 0.3486 - val_precision: 0.8504 - val_recall: 0.9946 - learning_rate: 2.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9336 - auc: 0.9836 - loss: 0.1660 - precision: 0.9781 - recall: 0.9299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.9336 - auc: 0.9836 - loss: 0.1659 - precision: 0.9781 - recall: 0.9299 - val_accuracy: 0.9434 - val_auc: 0.9911 - val_loss: 0.1741 - val_precision: 0.9928 - val_recall: 0.9290 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m131/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9359 - auc: 0.9830 - loss: 0.1623 - precision: 0.9858 - recall: 0.9270"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 103ms/step - accuracy: 0.9359 - auc: 0.9830 - loss: 0.1622 - precision: 0.9858 - recall: 0.9271 - val_accuracy: 0.9658 - val_auc: 0.9916 - val_loss: 0.1062 - val_precision: 0.9903 - val_recall: 0.9624 - learning_rate: 2.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 89ms/step - accuracy: 0.9460 - auc: 0.9883 - loss: 0.1363 - precision: 0.9878 - recall: 0.9391 - val_accuracy: 0.8584 - val_auc: 0.9810 - val_loss: 0.5142 - val_precision: 0.9983 - val_recall: 0.8054 - learning_rate: 2.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9375 - auc: 0.9835 - loss: 0.1644 - precision: 0.9774 - recall: 0.9378\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 115ms/step - accuracy: 0.9375 - auc: 0.9835 - loss: 0.1643 - precision: 0.9774 - recall: 0.9378 - val_accuracy: 0.9648 - val_auc: 0.9902 - val_loss: 0.1102 - val_precision: 0.9822 - val_recall: 0.9690 - learning_rate: 2.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - accuracy: 0.9502 - auc: 0.9891 - loss: 0.1292 - precision: 0.9879 - recall: 0.9446 - val_accuracy: 0.9570 - val_auc: 0.9925 - val_loss: 0.1512 - val_precision: 0.9972 - val_recall: 0.9442 - learning_rate: 4.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9541 - auc: 0.9915 - loss: 0.1154 - precision: 0.9901 - recall: 0.9475\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - accuracy: 0.9541 - auc: 0.9915 - loss: 0.1155 - precision: 0.9900 - recall: 0.9475 - val_accuracy: 0.9131 - val_auc: 0.9897 - val_loss: 0.3028 - val_precision: 0.9970 - val_recall: 0.8838 - learning_rate: 4.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 114ms/step - accuracy: 0.9559 - auc: 0.9920 - loss: 0.1118 - precision: 0.9892 - recall: 0.9510 - val_accuracy: 0.8887 - val_auc: 0.9770 - val_loss: 0.4545 - val_precision: 0.9984 - val_recall: 0.8503 - learning_rate: 8.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a20b363fd40>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# backbone.trainable = True\n",
    "# model.compile(\n",
    "#     loss='binary_crossentropy', \n",
    "#     optimizer=Adam(learning_rate=1e-5), \n",
    "#     metrics=[\n",
    "#         'accuracy',       \n",
    "#         tf.keras.metrics.Precision(name='precision'),\n",
    "#         tf.keras.metrics.Recall(name='recall'),\n",
    "#         tf.keras.metrics.AUC(name='auc')\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# используем коллбэки\n",
    "# 1. Настройка learning rate при обучении\n",
    "# 2. Сохранение лучшей версии модели\n",
    "# 3. Остановка обучения, если нет улучшений\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    df_train_processed,\n",
    "    validation_data=df_valid_processed,\n",
    "    class_weight=class_weights,\n",
    "    epochs=30,\n",
    "    callbacks=[reduce_lr, model_checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.7285 - auc: 0.6188 - loss: 0.9627 - precision: 0.4207 - recall: 0.6636  \n",
      "Test Loss: 0.5946863889694214\n",
      "Test Accuracy: 0.8381410241127014\n"
     ]
    }
   ],
   "source": [
    "# проверим модель на тесте\n",
    "results = model.evaluate(df_test_processed)\n",
    "print(\"Test Loss:\", results[0])\n",
    "print(\"Test Accuracy:\", results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "    ДО class_weights:\n",
    "    Test Loss: 0.6504877805709839\n",
    "    Test Accuracy: 0.6089743375778198\n",
    "\n",
    "    ПОСЛЕ class_weights:\n",
    "    Test Loss: 0.6858784556388855\n",
    "    Test Accuracy: 0.6330128312110901\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.99      0.58      0.73       234\n",
      "   PNEUMONIA       0.80      0.99      0.88       390\n",
      "\n",
      "    accuracy                           0.84       624\n",
      "   macro avg       0.89      0.79      0.81       624\n",
      "weighted avg       0.87      0.84      0.83       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# сделаем матрицу ошибок\n",
    "y_pred_proba = model.predict(df_test_processed)\n",
    "y_pred = (y_pred_proba > 0.5).astype('int32')\n",
    "y_true = np.concatenate([y for x, y in df_test_processed], axis=0)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Предсказанные метки')\n",
    "plt.ylabel('Истинные метки')\n",
    "plt.title('Матрица ошибок')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=['NORMAL', 'PNEUMONIA']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "  ДО class_weights:\n",
    "  0 - 17 - 217\n",
    "  1 - 27 - 363\n",
    "    | 0  |  1 |\n",
    "\n",
    "  ПОСЛЕ class_weights:\n",
    "  0 - 11 - 223\n",
    "  1 - 6 - 384\n",
    "    | 0  |  1 |\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "xray_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
